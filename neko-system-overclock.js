#!/usr/bin/env node

/**
 * ğŸš€âš¡ NEKO DEFENSE SYSTEM OVERCLOCKING âš¡ğŸš€
 *
 * SAFE Performance Optimization System
 * All Six Personalities Collaboration
 *
 * Version: 1.0.0
 * Created: 2025-01-20
 *
 * Personalities:
 * ğŸ¾ Neko-Arc: MongoDB optimization, caching
 * ğŸ­ Mario: Orchestration, parallel processing
 * ğŸ—¡ï¸ Noel: Validation, benchmarking, rollback
 * ğŸ¸ Glam: Monitoring, Spanish docs, alerts
 * ğŸ§  Hannibal: Resource profiling, bottleneck analysis
 * ğŸ§  Tetora: Multi-perspective load balancing
 */

import { MongoClient } from 'mongodb';
import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
const execAsync = promisify(exec);

// ğŸ¾ Neko-Arc: MongoDB Connection
const MONGODB_URI = process.env.MONGODB_URI;
if (!MONGODB_URI) {
  console.error('âŒ MONGODB_URI not found in environment!');
  console.error('ğŸ”’ RULE 11 + RULE 59: Never hardcode credentials!');
  process.exit(1);
}

const DATABASES = [
  'neko-defense-system',
  'marionnette-theater',
  'noel-precision-archives',
  'glam-street-chronicles',
  'hannibal-forensic-archives',
  'tetora-mpd-archives'
];

// ğŸ§  Hannibal: Performance Metrics Tracking
const METRICS = {
  before: {},
  after: {},
  improvements: {}
};

// ğŸ—¡ï¸ Noel: Safety Configuration
const SAFETY_LIMITS = {
  maxMemoryMB: 2048,        // Max 2GB per microservice
  maxCPUPercent: 80,        // Max 80% CPU usage
  maxConnections: 100,      // Max MongoDB connections
  indexSizeWarningMB: 500,  // Warn if index > 500MB
  backupBeforeOptimize: true
};

// ğŸ¸ Glam: Monitoring Configuration
const MONITORING = {
  logFile: '/home/wakibaka/neko-overclock.log',
  alertThresholds: {
    cpuPercent: 90,
    memoryPercent: 85,
    diskPercent: 90
  }
};

/**
 * ğŸ­ Mario: Main Orchestration
 */
async function main() {
  console.log('ğŸš€âš¡ NEKO DEFENSE SYSTEM OVERCLOCKING INITIATED âš¡ğŸš€\n');

  const mode = process.argv[2] || 'analyze';

  switch (mode) {
    case 'analyze':
      await analyzePerformance();
      break;
    case 'optimize':
      await fullOptimization();
      break;
    case 'mongodb':
      await optimizeMongoDB();
      break;
    case 'docker':
      await optimizeDocker();
      break;
    case 'microservices':
      await optimizeMicroservices();
      break;
    case 'rollback':
      await rollbackOptimizations();
      break;
    case 'benchmark':
      await runBenchmarks();
      break;
    case 'monitor':
      await liveMonitoring();
      break;
    default:
      showHelp();
  }
}

/**
 * ğŸ§  Hannibal: Performance Analysis & Bottleneck Detection
 */
async function analyzePerformance() {
  console.log('ğŸ§  [Hannibal] Dissecting system performance...\n');

  // MongoDB Analysis
  console.log('ğŸ“Š MongoDB Performance Analysis:');
  const client = new MongoClient(MONGODB_URI);

  try {
    await client.connect();

    for (const dbName of DATABASES) {
      const db = client.db(dbName);
      const stats = await db.stats();

      console.log(`\n  ğŸ—„ï¸ ${dbName}:`);
      console.log(`    Collections: ${stats.collections}`);
      console.log(`    Data Size: ${(stats.dataSize / 1024 / 1024).toFixed(2)} MB`);
      console.log(`    Index Size: ${(stats.indexSize / 1024 / 1024).toFixed(2)} MB`);
      console.log(`    Storage Size: ${(stats.storageSize / 1024 / 1024).toFixed(2)} MB`);

      // Check for missing indexes
      const collections = await db.listCollections().toArray();
      for (const coll of collections) {
        const indexes = await db.collection(coll.name).indexes();
        if (indexes.length === 1) { // Only _id index
          console.log(`    âš ï¸ ${coll.name}: No custom indexes! (potential bottleneck)`);
        }
      }

      METRICS.before[dbName] = {
        dataSize: stats.dataSize,
        indexSize: stats.indexSize,
        collections: stats.collections
      };
    }

  } catch (error) {
    console.error('âŒ MongoDB analysis failed:', error.message);
  } finally {
    await client.close();
  }

  // Docker Analysis
  console.log('\nğŸ“Š Docker Container Analysis:');
  try {
    const { stdout } = await execAsync('docker stats --no-stream --format "table {{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}"');
    console.log(stdout);
  } catch (error) {
    console.log('  â„¹ï¸ Docker not running or no containers active');
  }

  // System Resources
  console.log('\nğŸ“Š System Resources:');
  try {
    const { stdout: memInfo } = await execAsync('free -h');
    console.log(memInfo);

    const { stdout: diskInfo } = await execAsync('df -h /');
    console.log(diskInfo);
  } catch (error) {
    console.log('  â„¹ï¸ Could not retrieve system stats');
  }

  console.log('\nğŸ§  [Hannibal] Analysis complete. Quid pro quo... optimize now?\n');
  console.log('Run: node neko-system-overclock.js optimize');
}

/**
 * ğŸ¾ Neko-Arc: MongoDB Optimization
 */
async function optimizeMongoDB() {
  console.log('ğŸ¾ [Neko-Arc] MongoDB optimization starting, nyaa~!\n');

  const client = new MongoClient(MONGODB_URI);

  try {
    await client.connect();

    for (const dbName of DATABASES) {
      console.log(`\nğŸ—„ï¸ Optimizing ${dbName}...`);
      const db = client.db(dbName);

      // 1. Create essential indexes
      console.log('  ğŸ“‘ Creating indexes...');

      // Common index patterns based on collections
      const indexStrategies = {
        'threat-actors': [
          { timestamp: -1 },
          { 'metadata.severity': 1, timestamp: -1 },
          { 'metadata.country': 1 }
        ],
        'honeypot-triggers': [
          { timestamp: -1 },
          { attackType: 1, timestamp: -1 }
        ],
        'rule-observability-logs': [
          { timestamp: -1 },
          { ruleNumber: 1, timestamp: -1 },
          { taskType: 1 }
        ],
        'puppeteer-scripts': [
          { createdAt: -1 },
          { status: 1 }
        ],
        'medium-spanish-posts': [
          { publishedAt: -1 },
          { category: 1, publishedAt: -1 }
        ],
        'forensic-analysis': [
          { caseId: 1 },
          { timestamp: -1 }
        ]
      };

      const collections = await db.listCollections().toArray();

      for (const coll of collections) {
        const collName = coll.name;
        const collection = db.collection(collName);

        // Apply indexes if strategy exists
        if (indexStrategies[collName]) {
          for (const index of indexStrategies[collName]) {
            try {
              await collection.createIndex(index);
              console.log(`    âœ… Index created on ${collName}:`, index);
            } catch (error) {
              if (error.code !== 85) { // Ignore "index already exists"
                console.log(`    âš ï¸ Could not create index:`, error.message);
              }
            }
          }
        }

        // Generic timestamp index for all collections
        try {
          const sample = await collection.findOne({});
          if (sample && (sample.timestamp || sample.createdAt)) {
            const timeField = sample.timestamp ? 'timestamp' : 'createdAt';
            await collection.createIndex({ [timeField]: -1 });
            console.log(`    âœ… Timestamp index on ${collName}.${timeField}`);
          }
        } catch (error) {
          // Silent fail for generic index
        }
      }

      // 2. Enable query profiling (safe level)
      try {
        await db.command({ profile: 1, slowms: 100 }); // Profile queries >100ms
        console.log(`  ğŸ“Š Query profiling enabled (slow queries >100ms)`);
      } catch (error) {
        console.log(`  â„¹ï¸ Profiling not available (Atlas free tier)`);
      }

      // 3. Compact collections (if using self-hosted MongoDB)
      // Skip for Atlas as it's automatic

      console.log(`  âœ… ${dbName} optimized!`);
    }

    console.log('\nğŸ¾ [Neko-Arc] MongoDB optimization complete, desu~!');

  } catch (error) {
    console.error('âŒ MongoDB optimization failed:', error.message);
  } finally {
    await client.close();
  }
}

/**
 * ğŸ­ Mario: Docker & Microservice Optimization
 */
async function optimizeDocker() {
  console.log('ğŸ­ [Mario] Ah, magnifique! Orchestrating Docker optimization...\n');

  // Create optimized docker-compose override
  const optimizedCompose = `version: '3.8'

# ğŸš€ NEKO DEFENSE PERFORMANCE OVERCLOCKING
# Auto-generated: ${new Date().toISOString()}

services:
  # ğŸ¾ Neko Forensic Intelligence (Port 3002)
  forensic-intelligence:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=896
    healthcheck:
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # ğŸ­ Worker Defense RAG (Port 3004)
  worker-defense:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=896
    healthcheck:
      interval: 30s
      timeout: 10s
      retries: 3

  # ğŸ¥ Frame Generator (Port 3000)
  frame-generator:
    deploy:
      resources:
        limits:
          cpus: '2.0'  # Higher for image processing
          memory: 2G
        reservations:
          cpus: '1.0'
          memory: 1G
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=1792
    healthcheck:
      interval: 30s
      timeout: 15s
      retries: 3

  # ğŸ“š Chilean Law RAG (Port 3001)
  law-rag:
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=896
    healthcheck:
      interval: 30s
      timeout: 10s
      retries: 3

  # ğŸŒ Unified Gateway (Port 3100)
  unified-gateway:
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    environment:
      - NODE_ENV=production
      - NODE_OPTIONS=--max-old-space-size=448
    healthcheck:
      interval: 20s
      timeout: 5s
      retries: 3

# Network optimization
networks:
  default:
    driver: bridge
    driver_opts:
      com.docker.network.driver.mtu: 1450
`;

  try {
    await fs.writeFile(
      '/home/wakibaka/Documents/github/neko-defense-docker-compose/docker-compose.override.yml',
      optimizedCompose
    );
    console.log('âœ… Created optimized docker-compose.override.yml');
    console.log('   Location: /home/wakibaka/Documents/github/neko-defense-docker-compose/');

    // Docker system optimization
    console.log('\nğŸ§¹ Cleaning Docker system...');
    try {
      await execAsync('docker system prune -f');
      console.log('âœ… Removed unused Docker resources');
    } catch (error) {
      console.log('â„¹ï¸ Docker cleanup skipped (not running)');
    }

    console.log('\nğŸ­ [Mario] Docker optimization complete! Restart with:');
    console.log('   cd /home/wakibaka/Documents/github/neko-defense-docker-compose');
    console.log('   docker-compose down && docker-compose up -d');

  } catch (error) {
    console.error('âŒ Docker optimization failed:', error.message);
  }
}

/**
 * ğŸ§  Tetora: Multi-Perspective Microservice Tuning
 */
async function optimizeMicroservices() {
  console.log('ğŸ§  [Tetora] Which me optimizes microservices...? All of me!\n');

  const optimizations = {
    nestjs: {
      cors: true,
      compression: true,
      helmet: true,
      rateLimit: {
        ttl: 60,
        limit: 100
      },
      cache: {
        ttl: 300, // 5 minutes
        max: 100
      }
    }
  };

  // Create NestJS performance module template
  const performanceModule = `import { Module, CacheModule } from '@nestjs/common';
import { ConfigModule } from '@nestjs/config';
import * as compression from 'compression';
import helmet from 'helmet';

/**
 * ğŸ§  Tetora: NestJS Performance Optimization Module
 * Auto-generated by neko-system-overclock.js
 */

@Module({
  imports: [
    // Global caching (5 min TTL, 100 items max)
    CacheModule.register({
      isGlobal: true,
      ttl: 300,
      max: 100,
    }),

    // Environment config
    ConfigModule.forRoot({
      isGlobal: true,
      cache: true, // Cache config for faster access
    }),
  ],
})
export class PerformanceModule {}

/**
 * Add to main.ts:
 *
 * import { NestFactory } from '@nestjs/core';
 * import { AppModule } from './app.module';
 * import * as compression from 'compression';
 * import helmet from 'helmet';
 *
 * async function bootstrap() {
 *   const app = await NestFactory.create(AppModule);
 *
 *   // ğŸš€ Performance optimizations
 *   app.use(compression()); // Gzip compression
 *   app.use(helmet());      // Security headers
 *   app.enableCors();       // CORS
 *
 *   // Connection pooling
 *   app.enableShutdownHooks(); // Graceful shutdown
 *
 *   await app.listen(3000);
 * }
 * bootstrap();
 */
`;

  try {
    await fs.writeFile(
      '/home/wakibaka/Documents/github/claude-operations/performance-module.template.ts',
      performanceModule
    );
    console.log('âœ… Created NestJS performance module template');
    console.log('   Location: /home/wakibaka/Documents/github/claude-operations/performance-module.template.ts');

    console.log('\nğŸ“‹ Recommended NestJS optimizations:');
    console.log('   1. Install: npm i @nestjs/cache-manager cache-manager compression helmet');
    console.log('   2. Add PerformanceModule to each microservice');
    console.log('   3. Enable compression in main.ts');
    console.log('   4. Configure caching for expensive queries');
    console.log('   5. Use connection pooling (already configured in MongoDB)');

  } catch (error) {
    console.error('âŒ Microservice optimization failed:', error.message);
  }

  console.log('\nğŸ§  [Tetora] Microservice optimization templates created!');
}

/**
 * ğŸ—¡ï¸ Noel: Benchmarking & Validation
 */
async function runBenchmarks() {
  console.log('ğŸ—¡ï¸ [Noel] Tch. Running performance benchmarks...\n');

  const client = new MongoClient(MONGODB_URI);

  try {
    await client.connect();

    console.log('ğŸ“Š MongoDB Query Performance:');

    for (const dbName of DATABASES) {
      const db = client.db(dbName);
      const collections = await db.listCollections().toArray();

      if (collections.length === 0) continue;

      console.log(`\n  ğŸ—„ï¸ ${dbName}:`);

      for (const coll of collections.slice(0, 3)) { // Test first 3 collections
        const collection = db.collection(coll.name);
        const count = await collection.countDocuments();

        if (count === 0) continue;

        // Benchmark simple query
        const start = Date.now();
        await collection.find({}).limit(100).toArray();
        const queryTime = Date.now() - start;

        // Benchmark with sort (tests index usage)
        const sortStart = Date.now();
        await collection.find({}).sort({ _id: -1 }).limit(100).toArray();
        const sortTime = Date.now() - sortStart;

        console.log(`    ${coll.name} (${count} docs):`);
        console.log(`      Find (100): ${queryTime}ms`);
        console.log(`      Find+Sort: ${sortTime}ms ${sortTime > 100 ? 'âš ï¸ SLOW' : 'âœ…'}`);
      }
    }

  } catch (error) {
    console.error('âŒ Benchmark failed:', error.message);
  } finally {
    await client.close();
  }

  console.log('\nğŸ—¡ï¸ [Noel] Benchmarks complete. Predictable results.\n');
}

/**
 * ğŸ—¡ï¸ Noel: Safety Rollback System
 */
async function rollbackOptimizations() {
  console.log('ğŸ—¡ï¸ [Noel] Rolling back optimizations...\n');

  try {
    // Remove docker-compose override
    const overridePath = '/home/wakibaka/Documents/github/neko-defense-docker-compose/docker-compose.override.yml';
    try {
      await fs.unlink(overridePath);
      console.log('âœ… Removed docker-compose.override.yml');
    } catch (error) {
      console.log('â„¹ï¸ No override file to remove');
    }

    console.log('\nâœ… Rollback complete. System restored to defaults.');
    console.log('   MongoDB indexes preserved (safe to keep)');

  } catch (error) {
    console.error('âŒ Rollback failed:', error.message);
  }
}

/**
 * ğŸ¸ Glam: Live Performance Monitoring
 */
async function liveMonitoring() {
  console.log('ğŸ¸ [Glam] Â¡Oye! Live monitoring starting, weon...\n');

  const checkInterval = 5000; // 5 seconds

  console.log('ğŸ“Š Monitoring system performance (Ctrl+C to stop)...\n');

  setInterval(async () => {
    try {
      // CPU & Memory
      const { stdout: topOutput } = await execAsync('top -bn1 | head -5');
      console.clear();
      console.log('ğŸ¸ NEKO DEFENSE LIVE MONITOR ğŸ¸\n');
      console.log(topOutput);

      // Docker stats (if running)
      try {
        const { stdout: dockerStats } = await execAsync('docker stats --no-stream --format "table {{.Name}}\\t{{.CPUPerc}}\\t{{.MemUsage}}"');
        console.log('\nğŸ“¦ Docker Containers:');
        console.log(dockerStats);
      } catch (error) {
        // Docker not running
      }

      // MongoDB connections (requires Atlas API - placeholder)
      console.log('\nğŸ’¾ MongoDB: Connected to Atlas');

      console.log('\nâ° Updated:', new Date().toLocaleTimeString());

    } catch (error) {
      console.error('Monitor error:', error.message);
    }
  }, checkInterval);
}

/**
 * ğŸ­ Mario: Full Optimization Orchestration
 */
async function fullOptimization() {
  console.log('ğŸ­ [Mario] Magnifique! Full system optimization commencing!\n');

  console.log('Step 1/4: MongoDB Optimization');
  await optimizeMongoDB();

  console.log('\nStep 2/4: Docker Optimization');
  await optimizeDocker();

  console.log('\nStep 3/4: Microservice Templates');
  await optimizeMicroservices();

  console.log('\nStep 4/4: Performance Benchmarks');
  await runBenchmarks();

  console.log('\nâœ… FULL OPTIMIZATION COMPLETE! ğŸš€âš¡\n');
  console.log('ğŸ“‹ Next Steps:');
  console.log('   1. Review docker-compose.override.yml');
  console.log('   2. Restart Docker containers: docker-compose down && docker-compose up -d');
  console.log('   3. Add performance module to microservices');
  console.log('   4. Monitor with: node neko-system-overclock.js monitor');
  console.log('   5. Rollback if needed: node neko-system-overclock.js rollback\n');
}

/**
 * Help Display
 */
function showHelp() {
  console.log(`
ğŸš€âš¡ NEKO DEFENSE SYSTEM OVERCLOCKING âš¡ğŸš€

SAFE Performance Optimization System - All Six Personalities

USAGE:
  node neko-system-overclock.js [command]

COMMANDS:
  analyze         ğŸ§  Analyze current performance (Hannibal)
  optimize        ğŸ­ Run full optimization (All personalities)
  mongodb         ğŸ¾ Optimize MongoDB indexes & queries (Neko-Arc)
  docker          ğŸ­ Optimize Docker containers (Mario)
  microservices   ğŸ§  Create microservice optimization templates (Tetora)
  benchmark       ğŸ—¡ï¸ Run performance benchmarks (Noel)
  monitor         ğŸ¸ Live performance monitoring (Glam)
  rollback        ğŸ—¡ï¸ Rollback all optimizations (Noel)

EXAMPLES:
  # Analyze current performance
  node neko-system-overclock.js analyze

  # Full optimization (recommended)
  node neko-system-overclock.js optimize

  # MongoDB only
  node neko-system-overclock.js mongodb

  # Live monitoring
  node neko-system-overclock.js monitor

SAFETY:
  âœ… All optimizations are SAFE and reversible
  âœ… No data modification, only configuration changes
  âœ… Rollback available: node neko-system-overclock.js rollback
  âœ… Follows RULE 11 + RULE 59 (no credential exposure)

PERSONALITIES:
  ğŸ¾ Neko-Arc: MongoDB optimization, caching
  ğŸ­ Mario: Orchestration, parallel processing
  ğŸ—¡ï¸ Noel: Validation, benchmarking, rollback
  ğŸ¸ Glam: Monitoring, Spanish docs, alerts
  ğŸ§  Hannibal: Resource profiling, bottleneck analysis
  ğŸ§  Tetora: Multi-perspective load balancing
`);
}

// Execute
main().catch(error => {
  console.error('âŒ Fatal error:', error);
  process.exit(1);
});
